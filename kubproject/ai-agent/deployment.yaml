apiVersion: v1
kind: Namespace
metadata:
  name: ai-agents
---
apiVersion: v1
kind: Secret
metadata:
  name: ai-agent-secrets
  namespace: ai-agents
type: Opaque
stringData:
  # Replace with your actual API key
  OPENAI_API_KEY: "sk-your-key-here"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-agent-config
  namespace: ai-agents
data:
  MODEL_NAME: "gpt-4o-mini"
  MAX_TOKENS: "1000"
  TEMPERATURE: "0.7"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-agent
  namespace: ai-agents
  labels:
    app: ai-agent
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-agent
  template:
    metadata:
      labels:
        app: ai-agent
    spec:
      containers:
      - name: ai-agent
        image: python:3.11-slim
        command: ["/bin/bash", "-c"]
        args:
          - |
            mkdir -p /app &&
            pip install fastapi uvicorn openai --quiet &&
            cat > /app/main.py << 'PYEOF'
            from fastapi import FastAPI, HTTPException
            from pydantic import BaseModel
            import os
            from openai import OpenAI

            app = FastAPI(title="Simple AI Agent")
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

            class Query(BaseModel):
                message: str
                system_prompt: str = "You are a helpful assistant."

            class Response(BaseModel):
                response: str
                model: str
                tokens_used: int

            @app.get("/health")
            def health():
                return {"status": "healthy"}

            @app.get("/ready")
            def ready():
                api_key = os.getenv("OPENAI_API_KEY", "")
                if api_key and api_key != "sk-your-key-here":
                    return {"status": "ready"}
                return {"status": "not configured", "error": "API key not set"}

            @app.post("/chat", response_model=Response)
            def chat(query: Query):
                try:
                    response = client.chat.completions.create(
                        model=os.getenv("MODEL_NAME", "gpt-4o-mini"),
                        messages=[
                            {"role": "system", "content": query.system_prompt},
                            {"role": "user", "content": query.message}
                        ],
                        max_tokens=int(os.getenv("MAX_TOKENS", "1000")),
                        temperature=float(os.getenv("TEMPERATURE", "0.7"))
                    )
                    return Response(
                        response=response.choices[0].message.content,
                        model=response.model,
                        tokens_used=response.usage.total_tokens
                    )
                except Exception as e:
                    raise HTTPException(status_code=500, detail=str(e))

            @app.get("/")
            def root():
                return {
                    "name": "Simple AI Agent",
                    "endpoints": ["/chat", "/health", "/ready"],
                    "model": os.getenv("MODEL_NAME", "gpt-4o-mini")
                }
            PYEOF
            cd /app && uvicorn main:app --host 0.0.0.0 --port 8000
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-agent-secrets
              key: OPENAI_API_KEY
        - name: MODEL_NAME
          valueFrom:
            configMapKeyRef:
              name: ai-agent-config
              key: MODEL_NAME
        - name: MAX_TOKENS
          valueFrom:
            configMapKeyRef:
              name: ai-agent-config
              key: MAX_TOKENS
        - name: TEMPERATURE
          valueFrom:
            configMapKeyRef:
              name: ai-agent-config
              key: TEMPERATURE
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: ai-agent
  namespace: ai-agents
spec:
  type: NodePort
  selector:
    app: ai-agent
  ports:
  - port: 80
    targetPort: 8000
